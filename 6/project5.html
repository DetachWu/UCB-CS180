<!DOCTYPE html>
<html>

<head>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Project 5 - Fun With Diffusion Models!</title>
	<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@500;700&display=swap" rel="stylesheet">
	<style>
		body {
			font-family: 'Montserrat', Arial, sans-serif;
			margin: 0;
			background: #fff;
			color: #002676;
		}

		.header {
			background: #002676;
			color: #fff;
			padding: 16px 24px;
			display: flex;
			justify-content: space-between;
			align-items: center;
		}

		.container {
			max-width: 900px;
			margin: 32px auto;
			padding: 0 16px;
		}

		.hero {
			background: #FDB515;
			padding: 20px;
			border-radius: 12px;
			box-shadow: 0 4px 20px rgba(0, 0, 0, 0.06);
		}

		.hero h1 {
			margin: 0 0 8px 0;
		}

		.section {
			margin: 28px 0;
		}

		.section h2 {
			margin-top: 18px;
			margin-bottom: 8px;
			border-left: 6px solid #FDB515;
			padding-left: 10px;
		}

		.deliverables {
			background: #f7fafc;
			border: 1px dashed #cbd5e0;
			border-radius: 8px;
			padding: 12px;
			color: #1f3a8a;
			margin-top: 8px;
		}

		.image {
			text-align: center;
			margin: 12px 0;
		}

		.image img {
			max-width: 100%;
			height: auto;
			border-radius: 8px;
			border: 3px solid #fff;
			box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
		}

		.imggrid2 {
			display: grid;
			grid-template-columns: repeat(2, 1fr);
			gap: 12px;
			margin-top: 12px;
		}

		.imggrid3 {
			display: grid;
			grid-template-columns: repeat(3, 1fr);
			gap: 12px;
			margin-top: 12px;
		}

        .imggrid4 {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 12px;
            margin-top: 12px;
        }

		.imggrid5 {
			display: grid;
			grid-template-columns: repeat(5, 1fr);
			gap: 12px;
			margin-top: 12px;
		}

		.imggrid7 {
			display: grid;
			grid-template-columns: repeat(7, 1fr);
			gap: 12px;
			margin-top: 12px;
		}

		.imgstrip8 {
			margin-top: 16px;
		}

		.imgstrip8-grid {
			display: grid;
			grid-template-columns: repeat(8, minmax(0, 1fr));
			gap: 10px;
		}

		.imgstrip8-grid img {
			width: 100%;
			height: 100%;
			object-fit: cover;
		}

		.imgstrip8-caption {
			margin-top: 8px;
			text-align: center;
			font-size: 0.95rem;
			color: #334155;
		}

		@media (max-width: 960px) {
			.imgstrip8-grid {
				grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));
			}
		}
		/* match project2 layout for figure/image styles */
		figure {
			margin: 0;
			text-align: center;
		}

		figure img {
			max-width: 100%;
			height: auto;
			object-fit: contain;
			border-radius: 8px;
			border: 3px solid #fff;
			box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
			display: block;
			margin-left: auto;
			margin-right: auto;
		}

		figcaption {
			margin-top: 6px;
			font-size: 13px;
			color: #0f172a;
			font-weight: 600;
		}

		/* optional helpers used in project2 for fixed-height grids */
		.equal-height img {
			height: 300px;
			object-fit: cover;
		}

		.equal-height-little-long img {
			height: 400px;
			object-fit: cover;
		}

		.equal-height-long img {
			height: 500px;
			object-fit: cover;
		}

		.equal-height-short img {
			height: 200px;
			object-fit: cover;
		}

		code {
			background: #f1f5f9;
			padding: 2px 4px;
			border-radius: 4px;
			font-size: 0.9em;
		}

		.note {
			margin-top: 10px;
			color: #334155;
			font-size: 0.95rem;
		}

		.back {
			display: inline-block;
			margin-top: 16px;
			color: #002676;
			text-decoration: none;
			font-weight: 700;
		}
	</style>
	<!-- MathJax for rendering LaTeX equations in the page -->
	<script>
		window.MathJax = {
			tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
			svg: { fontCache: 'global' }
		};
	</script>
	<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>

<body>
	<div class="header">
		<div>Project 5: Fun With Diffusion Models!</div>
		<div>DetachWu</div>
	</div>

	<div class="container">
		<div class="hero">
			<h1>Fun With Diffusion Models!</h1>
		</div>

        <section id="Overview" class="section">
			<h2>Part A: The Power of Diffusion Models!</h2>
			<p>In part A you will play around with diffusion models, implement diffusion sampling loops, and use them for other tasks such as inpainting and creating optical illusions.</p>
		</section>

		<!-- A.1 -->
		<section id="0" class="section">
			<h2>0: Setup</h2>
			<div class="deliverables">
				<ul>
					<li>Come up with some interesting text prompts and generate their embeddings.</li>
                    <li>Choose 3 of your prompts to generate images and display the caption and the output of the model. Reflect on the quality of the outputs and their relationships to the text prompts. Make sure to try at least 2 different num_inference_steps values.</li>
                    <li>Report the random seed that you're using here. You should use the same seed all subsequent parts.</li>
				</ul>
			</div>
            <p><strong>My seed:</strong> 100</p>
            <p><strong>Prompts:</strong></p>
            <p>"an oil painting of people around a campfire"</p>
			<div class="imggrid2">
				<figure>
					<img src="./media/campfire_20.png" alt="im1" />
					<figcaption>campfire_20</figcaption>
				</figure>
				<figure>
					<img src="./media/campfire_50.png" alt="im2" />
					<figcaption>campfire_50</figcaption>
				</figure>
			</div>
            <p>"a rocket ship"</p>
            <div class="imggrid2">
				<figure>
					<img src="./media/rocket_20.png" alt="im1" />
					<figcaption>rocket_20</figcaption>
				</figure>
				<figure>
					<img src="./media/rocket_50.png" alt="im2" />
					<figcaption>rocket_50</figcaption>
				</figure>
			</div>
            <p>"a lithograph of waterfalls"</p>
            <div class="imggrid2">
				<figure>
					<img src="./media/waterfalls_20.png" alt="im1" />
					<figcaption>waterfalls_20</figcaption>
				</figure>
				<figure>
					<img src="./media/waterfalls_50.png" alt="im2" />
					<figcaption>waterfalls_50</figcaption>
				</figure>
			</div>
            <p>Higher num_inference_steps values often yield slightly better quality, characterized by richer detail. However, they can also produce elements that are physically unrealistic. For these specific sets, I actually prefer the images generated at 20 steps.</p>
		</section>

		<!-- A.2 -->
		<section id="1.1" class="section">
			<h2>1.1: Implementing the Forward Process</h2>
			<div class="deliverables">
				<ul>
					<li>Implement the <code>noisy_im = forward(im, t)</code> function.</li>
					<li>Show the Campanile at noise level [250, 500, 750].</li>
				</ul>
			</div>

			<div class="imggrid4">
		        <figure>
					<img src="./media/campanile_original.png" alt="im1" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/campanile_250.png" alt="im2" style="width: 100%;" />
					<figcaption>t = 250</figcaption>
				</figure>
                <figure>
					<img src="./media/campanile_500.png" alt="im1" style="width: 100%;" />
					<figcaption>t = 500</figcaption>
				</figure>
				<figure>
					<img src="./media/campanile_750.png" alt="im2" style="width: 100%;" />
					<figcaption>t = 750</figcaption>
				</figure>
			</div>
			<p>I implemented the forward diffusion process by scaling the clean image with the square root of the cumulative product of alphas at timestep t and adding Gaussian noise weighted by the corresponding variance term. This simulates the progressive corruption of the image over time.</p>
		</section>

		<!-- A.3 -->
		<section id="1.2" class="section">
			<h2>1.2 Classical Denoising</h2>
			<div class="deliverables">
				<ul>
					<li>For each of the 3 noisy Campanile images from the previous part, show your best Gaussian-denoised version side by side.</li>
				</ul>
			</div>

			<div class="image">
                <img src="./media/1.2.png" alt="Classical Denoising" />
            </div>

			<p>In this part, I generated noisy images at timesteps 250, 500, and 750 using the forward diffusion process and applied a Gaussian blur as a simple, classical denoising method. However, the results were poor—while the blur slightly smoothed the noise, it also destroyed fine details and failed to restore meaningful structure. This shows that traditional image filters are inadequate for reversing diffusion noise.</p>
		</section>

		<!-- A.4 -->
		<section id="1.3" class="section">
			<h2>1.3 One-Step Denoising</h2>
			<div class="deliverables">
				<ul>
					<li>For the 3 noisy images from 1.2 (t = [250, 500, 750]):</li>
					<ul>
						<li>Use your forward function to add noise to your Campanile.</li>
						<li>Estimate the noise in the new noisy image, by passing it through stage_1.unet</li>
						<li>Remove the noise from the noisy image to obtain an estimate of the original image.</li>
						<li>Visualize the original image, the noisy image, and the estimate of the original image</li>
					</ul>
				</ul>
			</div>
            <div class="image">
                <img src="./media/1.3.png" alt="One-Step Denoising" />
			</div>
			<p>I added one-step denoising with the UNet: for each <em>t</em> (250, 500, 750) I first noised the image, then used the UNet with the null/unconditional prompt embedding to predict &epsilon; and computed 
  <code>&#x005E;x<sub>0</sub> = (x<sub>t</sub> - &radic;(1 - &amacr;<sub>t</sub>)&nbsp;&epsilon;) / &radic;(&amacr;<sub>t</sub>)</code>.
  In practice, this learned denoiser clearly outperforms the classical Gaussian blur, but a single step only partially recovers structure—it works reasonably well at <em>t</em> = 250 and quickly breaks down by <em>t</em> = 750.
  When t &gt; 500, the one-step reconstruction deviates noticeably from the original—details vanish.</p>

		</section>

		<!-- A.5 -->
		<section id="1.4" class="section">
			<h2>1.4 Iterative Denoising</h2>
			<div class="deliverables">
				<ul>
					<li>Using i_start = 10:</li>
					<ul>
						<li>Create strided_timesteps: a list of monotonically decreasing timesteps, starting at 990, with a stride of 30, eventually reaching 0. Also initialize the timesteps using the function stage_1.scheduler.set_timesteps(timesteps=strided_timesteps)</li>
						<li>Complete the iterative_denoise function</li>
						<li>Show the noisy Campanile every 5th loop of denoising (it should gradually become less noisy)</li>
						<li>Show the final predicted clean image, using iterative denoising</li>
						<li>Show the predicted clean image using only a single denoising step, as was done in the previous part. This should look much worse.</li>
						<li>Show the predicted clean image using gaussian blurring, as was done in part 1.2.</li>
				</ul>
			</div>

			<div class="imggrid5">
				<figure>
					<img src="./media/t=660.png" alt="t=660" style="width: 100%;" />
					<figcaption>t=660</figcaption>
				</figure>
				<figure>
					<img src="./media/t=510.png" alt="t=510" style="width: 100%;" />
					<figcaption>t=510</figcaption>
				</figure>
				<figure>
					<img src="./media/t=360.png" alt="t=360" style="width: 100%;" />
					<figcaption>t=360</figcaption>
				</figure>
				<figure>
					<img src="./media/t=210.png" alt="t=210" style="width: 100%;" />
					<figcaption>t=210</figcaption>
				</figure>
				<figure>
					<img src="./media/t=60.png" alt="t=60" style="width: 100%;" />
					<figcaption>t=60</figcaption>
				</figure>
			</div>

			<div class="image">
				<img src="./media/1.4.png" alt="Iterative Denoising" />
			</div>

			<p>In this implementation, I first created a strided sequence of timesteps and built an iterative denoising loop that gradually refines the noisy image using the UNet’s noise and variance predictions.</p>
<p>At each step, I computed <em>x</em><sub>0</sub> and the next image <em>x</em><sub>t′</sub> via the DDPM update equation, adding the learned variance for stochasticity.</p>
<p>I also implemented a one-step denoising and a Gaussian blur baseline for comparison.</p>
<p>Overall, the iterative reverse diffusion reconstructs the image more faithfully than the single-step or classical filtering alternatives.</p>

		</section>

		<section id="1.5" class="section">
			<h2>1.5 Diffusion Model Sampling</h2>
			<div class="deliverables">
				<ul>
					<li>Show 5 sampled images.</li>
				</ul>
			</div>

			<div class="image">
				<img src="./media/1.5.png" alt="Diffusion Model Sampling" />
			</div>
		</section>

		<section id="1.6" class="section">
			<h2>1.6 Classifier Free Guidance</h2>
			<div class="deliverables">
				<ul>
					<li>Implement the iterative_denoise_cfg function</li>
					<li>Show 5 images of "a high quality photo" with a CFG scale of 7. Now this prompt becomes a condition (but fairly weak) to generate conditional noise! You will use your customized prompts as stronger conditions in part 1.7 - part 1.9.</li>
				</ul>
			</div>

			<div class="image">
				<img src="./media/1.6.png" alt="Classifier Free Guidance" />
			</div>
			<p>The point that impresses me most is that the shadow of the mountain in the water in sample 2 is accurate!</p>
		</section>

		<section id="1.7" class="section">
			<h2>1.7 Image-to-image Translation</h2>
			<div class="deliverables">
				<ul>
					<li>Edits of the Campanile image, using the given prompt at noise levels [1, 3, 5, 7, 10, 20] with the conditional text prompt "a high quality photo"</li>
					<li>Edits of 2 of your own test images, using the same procedure.</li>
				</ul>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7_1.png" alt="i_start=1" style="width: 100%;" />
					<figcaption>i_start=1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_3.png" alt="i_start=3" style="width: 100%;" />
					<figcaption>i_start=3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_5.png" alt="i_start=5" style="width: 100%;" />
					<figcaption>i_start=5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_7.png" alt="i_start=7" style="width: 100%;" />
					<figcaption>i_start=7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_10.png" alt="i_start=10" style="width: 100%;" />
					<figcaption>i_start=10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_20.png" alt="i_start=20" style="width: 100%;" />
					<figcaption>i_start=20</figcaption>
				</figure>
				<figure>
					<img src="./media/campanile_original.png" alt="Original Image" style="width: 100%;" />
					<figcaption>Original Image</figcaption>
				</figure>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7_1_2.png" alt="i_start=1" style="width: 100%;" />
					<figcaption>i_start=1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_3_2.png" alt="i_start=3" style="width: 100%;" />
					<figcaption>i_start=3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_5_2.png" alt="i_start=5" style="width: 100%;" />
					<figcaption>i_start=5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_7_2.png" alt="i_start=7" style="width: 100%;" />
					<figcaption>i_start=7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_10_2.png" alt="i_start=10" style="width: 100%;" />
					<figcaption>i_start=10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_20_2.png" alt="i_start=20" style="width: 100%;" />
					<figcaption>i_start=20</figcaption>
				</figure>
				<figure>
					<img src="./media/photo3.jpg" alt="Original Image" style="width: 100%;" />
					<figcaption>Original Image</figcaption>
				</figure>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7_1_3.png" alt="i_start=1" style="width: 100%;" />
					<figcaption>i_start=1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_3_3.png" alt="i_start=3" style="width: 100%;" />
					<figcaption>i_start=3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_5_3.png" alt="i_start=5" style="width: 100%;" />
					<figcaption>i_start=5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_7_3.png" alt="i_start=7" style="width: 100%;" />
					<figcaption>i_start=7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_10_3.png" alt="i_start=10" style="width: 100%;" />
					<figcaption>i_start=10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7_20_3.png" alt="i_start=20" style="width: 100%;" />
					<figcaption>i_start=20</figcaption>
				</figure>
				<figure>
					<img src="./media/photo4.jpg" alt="Original Image" style="width: 100%;" />
					<figcaption>Original Image</figcaption>
				</figure>
			</div>
		</section>

		<section id="1.7.1" class="section">
			<h2>1.7.1 Editing Hand-Drawn and Web Images</h2>
			<div class="deliverables">
				<ul>
					<li>1 image from the web of your choice, edited using the above method for noise levels [1, 3, 5, 7, 10, 20] (and whatever additional noise levels you want)</li>
					<li>2 hand drawn images, edited using the above method for noise levels [1, 3, 5, 7, 10, 20] (and whatever additional noise levels you want)</li>
				</ul>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7.1_1_original.png" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_1.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_2.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_3.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_4.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_5.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_1_6.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7.1_2_original.png" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_1.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_2.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_3.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_4.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_5.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_2_6.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/1.7.1_3_original.png" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_1.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_2.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_3.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_4.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_5.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.1_3_6.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>
		</section>

		<section id="1.7.2" class="section">
			<h2>1.7.2 Inpainting</h2>
			<div class="deliverables">
				<ul>
					<li>A properly implemented inpaint function</li>
					<li>The Campanile inpainted (feel free to use your own mask)</li>
					<li>2 of your own images edited (come up with your own mask)</li>
				</ul>
			</div>


			<div class="image">
				<img src="./media/1.7.2_1.png" alt="Inpainting Example" />
			</div>
			<div class="image">
				<img src="./media/1.7.2_2.png" alt="Inpainting Example" />
			</div>
			<div class="image">
				<img src="./media/1.7.2_3.png" alt="Inpainting Example" />
			</div>
		</section>

		<section id="1.7.3" class="section">
			<h2>1.7.3 Text-Conditional Image-to-image Translation</h2>
			<div class="deliverables">
				<ul>
					<li>Edits of the Campanile, using the given prompt at noise levels [1, 3, 5, 7, 10, 20]</li>
					<li>Edits of 2 of your own test images, using the same procedure</li>
				</ul>
			</div>
			<p>Prompt: "an oil painting of people around a campfire"</p>
			<div class="imggrid7">
				<figure>
					<img src="./media/campanile_original.png" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_1.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_2.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_3.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_4.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_5.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_6.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>
			<div class="imggrid7">
				<figure>
					<img src="./media/photo1.png" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_1_2.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_2_2.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_3_2.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_4_2.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_5_2.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_6_2.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>
			<div class="imggrid7">
				<figure>
					<img src="./media/photo2.jpg" alt="original" style="width: 100%;" />
					<figcaption>original</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_1_3.png" alt="1" style="width: 100%;" />
					<figcaption>1</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_2_3.png" alt="3" style="width: 100%;" />
					<figcaption>3</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_3_3.png" alt="5" style="width: 100%;" />
					<figcaption>5</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_4_3.png" alt="7" style="width: 100%;" />
					<figcaption>7</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_5_3.png" alt="10" style="width: 100%;" />
					<figcaption>10</figcaption>
				</figure>
				<figure>
					<img src="./media/1.7.3_6_3.png" alt="20" style="width: 100%;" />
					<figcaption>20</figcaption>
				</figure>
			</div>
		</section>
		<section id="1.8" class="section">
			<h2>1.8 Visual Anagrams</h2>
			<div class="deliverables">
				<ul>
					<li>Correctly implemented visual_anagrams function</li>
					<li>2 illusions of your choice that change appearance when you flip it upside down</li>
				</ul>
			</div>
			<div class="image">
				<figure>
					<img src="./media/1.8.png" alt="illusion" />
				</figure>
			</div>
		</section>

		<section id="1.9" class="section">
			<h2>1.9 Hybrid Images</h2>
			<div class="deliverables">
				<ul>
					<li>Correctly implemented make_hybrids function</li>
					<li>2 hybrid images of your choosing</li>
				</ul>
			</div>
			<p>Low Frequency Prompt: "a lithograph of waterfalls"</p>
			<p>High Frequency Prompt: "an oil painting of people around a campfire"</p>
			<div class="image">
				<figure>
					<img src="./media/1.9_1.png" alt="hybrid image 1" style="width: 40%;" />
				</figure>
			</div>
			<p>Low Frequency Prompt: "a photo of a dog"</p>
			<p>High Frequency Prompt: "a man wearing a hat"</p>
			<div class="image">
				<figure>
					<img src="./media/1.9_2.png" alt="hybrid image 2" style="width: 40%;" />
				</figure>
			</div>
		<!-- Part B: User-added section with four subsections B.1 - B.4 -->
		<section id="PartB" class="section">
			<h2>Part B: Flow Matching from Scratch!</h2>
			<p>You will train your own flow matching model on MNIST. In this part, you will build and train a UNet, which is more complex than the MLP you implemented in the NeRF project.</p>
		
		<h2>Part 1: Training a Single-Step Denoising UNet</h2>
		<section id="1.1" class="section">
			<h2>1.1 Implementing the UNet</h2>
			<p>In this project, we implement the denoiser as a UNet. It consists of a few downsampling and upsampling blocks with skip connections.</p>
			<div class="image">
				<figure>
					<img src="./media/B1.1_1.png" alt="UNet architecture" style="width: 100%;" />
				</figure>
			</div>
			<p>The diagram above uses a number of standard tensor operations defined as follows:</p>
			<div class="image">
				<figure>
					<img src="./media/B1.1_2.png" alt="standard tensor operations" style="width: 100%;" />
				</figure>
			</div>
		</section>

		<section id="1.2" class="section">
			<h2>1.2 Using the UNet to Train a Denoiser</h2>
				<div class="deliverables">
				<ul>
					<li>A visualization of the noising process using [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0].</li>
				</ul>
				</div>
				<div class="image">
					<img src="./media/B1.2.png" alt="1.2" />
				</div>
				<p>I added Gaussian noise with different standard deviations (σ) to an MNIST image to visualize how increasing noise progressively degrades image quality. This helps illustrate the effect of the noise level on data corruption in the diffusion process.</p>
		</section>

		<section id="1.2.1" class="section">
			<h2>1.2.1 Training</h2>
			<div class="deliverables">
				<ul>
					<li>A training loss curve plot every few iterations during the whole training process of σ=0.5.</li>
					<li>Sample results on the test set with noise level 0.5 after the first and the 5-th epoch.</li>
				</ul>
			</div>
			<p>Training Loss Curve:</p>
			<div class="image">
					<img src="./media/1.2.1_training_curve.png" alt="training curve" />
			</div>
			<p>Sample Results:</p>
			<div class="imgstrip8">
				<div class="imgstrip8-grid">
					<img src="./media/1.png" alt="7">
					<img src="./media/2.png" alt="2">
					<img src="./media/3.png" alt="1">
					<img src="./media/4.png" alt="0">
					<img src="./media/5.png" alt="4">
					<img src="./media/6.png" alt="1">
					<img src="./media/7.png" alt="4">
					<img src="./media/8.png" alt="9">
				</div>
				<div class="imgstrip8-caption">Clean</div>
			</div>
			<div class="imgstrip8">
				<div class="imgstrip8-grid">
					<img src="./media/9.png" alt="7">
					<img src="./media/10.png" alt="2">
					<img src="./media/11.png" alt="1">
					<img src="./media/12.png" alt="0">
					<img src="./media/13.png" alt="4">
					<img src="./media/14.png" alt="1">
					<img src="./media/15.png" alt="4">
					<img src="./media/16.png" alt="9">
				</div>
				<div class="imgstrip8-caption">Noisy</div>
			</div>
			<div class="imgstrip8">
				<div class="imgstrip8-grid">
					<img src="./media/17.png" alt="7">
					<img src="./media/18.png" alt="2">
					<img src="./media/19.png" alt="1">
					<img src="./media/20.png" alt="0">
					<img src="./media/21.png" alt="4">
					<img src="./media/22.png" alt="1">
					<img src="./media/23.png" alt="4">
					<img src="./media/24.png" alt="9">
				</div>
				<div class="imgstrip8-caption">Denoised</div>
			</div>
		</section>

		<section id="1.2.2" class="section">
			<h2>1.2.2 Out-of-Distribution Testing</h2>
			<div class="deliverables">
				<ul>
					<li>Sample results on the test set with out-of-distribution noise levels after the model is trained. Keep the same image and vary σ = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0].</li>
				</ul>
			</div>
			<p>Sample results:</p>
			<div class="imggrid7">
				<figure>
					<img src="./media/25.png" alt="0.0" style="width: 100%;" />
					<figcaption>Clean(σ=0.0)</figcaption>
				</figure>
				<figure>
					<img src="./media/26.png" alt="0.2" style="width: 100%;" />
					<figcaption>Clean(σ=0.2)</figcaption>
				</figure>
				<figure>
					<img src="./media/27.png" alt="0.4" style="width: 100%;" />
					<figcaption>Clean(σ=0.4)</figcaption>
				</figure>
				<figure>
					<img src="./media/28.png" alt="0.5" style="width: 100%;" />
					<figcaption>Clean(σ=0.5)</figcaption>
				</figure>
				<figure>
					<img src="./media/29.png" alt="0.6" style="width: 100%;" />
					<figcaption>Clean(σ=0.6)</figcaption>
				</figure>
				<figure>
					<img src="./media/30.png" alt="0.8" style="width: 100%;" />
					<figcaption>Clean(σ=0.8)</figcaption>
				</figure>
				<figure>
					<img src="./media/31.png" alt="1.0" style="width: 100%;" />
					<figcaption>Clean(σ=1.0)</figcaption>
				</figure>
			</div>
			<div class="imggrid7">
				<figure>
					<img src="./media/32.png" alt="0.0" style="width: 100%;" />
					<figcaption>Noisy(σ=0.0)</figcaption>
				</figure>
				<figure>
					<img src="./media/33.png" alt="0.2" style="width: 100%;" />
					<figcaption>Noisy(σ=0.2)</figcaption>
				</figure>
				<figure>
					<img src="./media/34.png" alt="0.4" style="width: 100%;" />
					<figcaption>Noisy(σ=0.4)</figcaption>
				</figure>
				<figure>
					<img src="./media/35.png" alt="0.5" style="width: 100%;" />
					<figcaption>Noisy(σ=0.5)</figcaption>
				</figure>
				<figure>
					<img src="./media/36.png" alt="0.6" style="width: 100%;" />
					<figcaption>Noisy(σ=0.6)</figcaption>
				</figure>
				<figure>
					<img src="./media/37.png" alt="0.8" style="width: 100%;" />
					<figcaption>Noisy(σ=0.8)</figcaption>
				</figure>
				<figure>
					<img src="./media/38.png" alt="1.0" style="width: 100%;" />
					<figcaption>Noisy(σ=1.0)</figcaption>
				</figure>
			</div>

			<div class="imggrid7">
				<figure>
					<img src="./media/39.png" alt="0.0" style="width: 100%;" />
					<figcaption>Denoised(σ=0.0)</figcaption>
				</figure>
				<figure>
					<img src="./media/40.png" alt="0.2" style="width: 100%;" />
					<figcaption>Denoised(σ=0.2)</figcaption>
				</figure>
				<figure>
					<img src="./media/41.png" alt="0.4" style="width: 100%;" />
					<figcaption>Denoised(σ=0.4)</figcaption>
				</figure>
				<figure>
					<img src="./media/42.png" alt="0.5" style="width: 100%;" />
					<figcaption>Denoised(σ=0.5)</figcaption>
				</figure>
				<figure>
					<img src="./media/43.png" alt="0.6" style="width: 100%;" />
					<figcaption>Denoised(σ=0.6)</figcaption>
				</figure>
				<figure>
					<img src="./media/44.png" alt="0.8" style="width: 100%;" />
					<figcaption>Denoised(σ=0.8)</figcaption>
				</figure>
				<figure>
					<img src="./media/45.png" alt="1.0" style="width: 100%;" />
					<figcaption>Denoised(σ=1.0)</figcaption>
				</figure>
			</div>
		</section>

		<section id="1.2.3" class="section">
			<h2>1.2.3 Denoising Pure Noise</h2>
			<div class="deliverables">
				<ul>
					<li>A training loss curve plot every few iterations during the whole training process that denoises pure noise.</li>
					<li>Sample results on pure noise after the first and the 5-th epoch.</li>
					<li>A brief description of the patterns observed in the generated outputs and explanations for why they may exist.</li>
				</ul>
			</div>
			<p>Training Loss Curve:</p>
			<div class="image">
					<img src="./media/1.2.3_training_curve.png" alt="training curve" />
			</div>
			<p>Sample Results:</p>
			<div class="imgstrip8">
				<div class="imgstrip8-grid">
					<img src="./media/46.png" alt="Generated 1">
					<img src="./media/47.png" alt="Generated 2">
					<img src="./media/48.png" alt="Generated 3">
					<img src="./media/49.png" alt="Generated 4">
					<img src="./media/50.png" alt="Generated 5">
					<img src="./media/51.png" alt="Generated 6">
					<img src="./media/52.png" alt="Generated 7">
					<img src="./media/53.png" alt="Generated 8">
				</div>
				<div class="imgstrip8-grid">
					<img src="./media/54.png" alt="Generated 1">
					<img src="./media/55.png" alt="Generated 2">
					<img src="./media/56.png" alt="Generated 3">
					<img src="./media/57.png" alt="Generated 4">
					<img src="./media/58.png" alt="Generated 5">
					<img src="./media/59.png" alt="Generated 6">
					<img src="./media/60.png" alt="Generated 7">
					<img src="./media/61.png" alt="Generated 8">
				</div>
				<div class="imgstrip8-caption">After 1th Epoch</div>
			</div>
			<div class="imgstrip8">
				<div class="imgstrip8-grid">
					<img src="./media/62.png" alt="Generated 1">
					<img src="./media/63.png" alt="Generated 2">
					<img src="./media/64.png" alt="Generated 3">
					<img src="./media/65.png" alt="Generated 4">
					<img src="./media/66.png" alt="Generated 5">
					<img src="./media/67.png" alt="Generated 6">
					<img src="./media/68.png" alt="Generated 7">
					<img src="./media/69.png" alt="Generated 8">
				</div>
				<div class="imgstrip8-grid">
					<img src="./media/70.png" alt="Generated 1">
					<img src="./media/71.png" alt="Generated 2">
					<img src="./media/72.png" alt="Generated 3">
					<img src="./media/73.png" alt="Generated 4">
					<img src="./media/74.png" alt="Generated 5">
					<img src="./media/75.png" alt="Generated 6">
					<img src="./media/76.png" alt="Generated 7">
					<img src="./media/77.png" alt="Generated 8">
				</div>
				<div class="imgstrip8-caption">After 5th Epoch</div>
			</div>
			<p>The generated outputs from the pure-noise denoising model tend to appear blurry, low-contrast, and look like all the digits stacked together. This happens because the model is trained to map random Gaussian noise directly to clean images without any conditioning or timestep information—essentially an ill-posed task. Since there is no correlation between the noise input and the target image, the network learns to output the dataset’s mean structure or smooth patterns, minimizing MSE loss but failing to produce meaningful reconstructions.</p>
			
			<h2>Part 2: Training a Flow Matching Model</h2>
			<section id="2.1" class="section">
				<h2>2.1 Adding Time Conditioning to UNet</h2>
				<p>Time-Conditioned UNet Architecture:</p>
				<div class="image">
					<img src="./media/2.1.png" alt="Time-Conditioned UNet Architecture" />
				</div>
				<p>This uses a new operator called FCBlock (fully-connected block) which we use to inject the conditioning signal into the UNet:</p>
				<div class="image">
					<img src="./media/2.1.2.png" alt="FCBlock Illustration" />
				</div>
			</section>

			<section id="2.2" class="section">
				<h2>2.2 Training the UNet</h2>
				<div class="deliverables">
					<ul>
						<li>A training loss curve plot for the time-conditioned UNet over the whole training process.</li>
					</ul>
				</div>
				<p>Training Loss Curve:</p>
				<div class="image">
						<img src="./media/2.2.png" alt="training curve" />
				</div>
			</section>

			<section id="2.3" class="section">
				<h2>2.3 Sampling from the UNet</h2>
				<div class="deliverables">
					<ul>
						<li>Sampling results from the time-conditioned UNet for 1, 5, and 10 epochs. The results should not be perfect, but reasonably good.</li>
					</ul>
				</div>
				<p>Sampling Results:</p>
				<div class="image">
					<img src="./media/epoch1.png" alt="epoch 1" />
					<figcaption>epoch 1</figcaption>
				</div>
				<div class="image">
					<img src="./media/epoch5.png" alt="epoch 5" />
					<figcaption>epoch 5</figcaption>
				</div>
				<div class="image">
					<img src="./media/epoch10.png" alt="epoch 10" />
					<figcaption>epoch 10</figcaption>
				</div>
			</section>



			<section id="2.4" class="section">
				<h2>2.4 Adding Class-Conditioning to UNet</h2>
				<p>I extended the UNet architecture to incorporate <strong>class conditioning</strong>. Each digit class (0–9) is encoded as a one-hot vector and passed through two fully connected blocks to generate class embeddings. During training, I applied <em>classifier-free guidance</em> by randomly masking out a portion of the class information, allowing the model to learn both conditional and unconditional behaviors.</p>

				<p>The conditioning signals are injected into the network at key points as follows:</p>

				<p style="text-align:center; font-style:italic; margin-top:10px;">
				unflatten = c1 × unflatten + t1<br>
				up1 = c2 × up1 + t2
				</p>

			</section>

			<section id="2.5" class="section">
				<h2>2.5 Training the UNet</h2>
				<div class="deliverables">
					<ul>
						<li>A training loss curve plot for the class-conditioned UNet over the whole training process.</li>
					</ul>
				</div>
				<p>Training Loss Curve:</p>
				<div class="image">
						<img src="./media/2.5.png" alt="training curve" />
				</div>
			</section>

			<section id="2.6" class="section">
				<h2>2.6 Sampling from the UNet</h2>
				<div class="deliverables">
					<ul>
						<li>Sampling results from the class-conditioned UNet for 1, 5, and 10 epochs. Class-conditioning lets us converge faster, hence why we only train for 10 epochs. Generate 4 instances of each digit as shown above.</li>
						<li>Can we get rid of the annoying learning rate scheduler? Simplicity is the best. Please try to maintain the same performance after removing the exponential learning rate scheduler. Show your visualization after training without the scheduler and provide a description of what you did to compensate for the loss of the scheduler.</li>
					</ul>
				</div>
				<p>Sampling Results(scheduler):</p>
				<div class="image">
					<img src="./media/sch_epoch1.png" alt="epoch 1 with scheduler" />
					<figcaption>epoch 1 with scheduler</figcaption>
				</div>
				<div class="image">
					<img src="./media/sch_epoch5.png" alt="epoch 5 with scheduler" />
					<figcaption>epoch 5 with scheduler</figcaption>
				</div>
				<div class="image">
					<img src="./media/sch_epoch10.png" alt="epoch 10 with scheduler" />
					<figcaption>epoch 10 with scheduler</figcaption>
				</div>
				<p>To test "Can we get rid of the annoying learning rate scheduler?" I remove the scheduler and reduce the learning rate a bit.(1e-2 -> 3e-3) And use torch.nn.utils.clip_grad_norm_(cunet_ns.parameters(), 1.0) to ramain the training stable.</p>
				<p>Sampling Results(no scheduler):</p>
				<div class="image">
					<img src="./media/nosch_epoch1.png" alt="epoch 1 without scheduler" />
					<figcaption>epoch 1 without scheduler</figcaption>
				</div>
				<div class="image">
					<img src="./media/nosch_epoch5.png" alt="epoch 5 without scheduler" />
					<figcaption>epoch 5 without scheduler</figcaption>
				</div>
				<div class="image">
					<img src="./media/nosch_epoch10.png" alt="epoch 10 without scheduler" />
					<figcaption>epoch 10 without scheduler</figcaption>
				</div>
			</section>
		</section>

		<a class="back" href="../index.html">← Back to Course Home</a>
	</div>
</body>

</html>
